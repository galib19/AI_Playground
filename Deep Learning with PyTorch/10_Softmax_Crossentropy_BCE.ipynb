{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMdESUQUtWJNgvCSgR9/eLR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"EyFZ0Oa2HdoQ","executionInfo":{"status":"ok","timestamp":1711445851730,"user_tz":240,"elapsed":7643,"user":{"displayName":"Asadullah Hill Galib","userId":"04918573300927859168"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np"]},{"cell_type":"code","source":["def softmax(x):\n","  return np.exp(x)/np.sum(np.exp(x) ,axis =0)"],"metadata":{"id":"3PFrbcPHHwum","executionInfo":{"status":"ok","timestamp":1711445883463,"user_tz":240,"elapsed":130,"user":{"displayName":"Asadullah Hill Galib","userId":"04918573300927859168"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["x = np.array([2.0, 1.0, 0.1])\n","outputs = softmax(x)\n","outputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NRbzH0eaH7iC","executionInfo":{"status":"ok","timestamp":1711445918780,"user_tz":240,"elapsed":206,"user":{"displayName":"Asadullah Hill Galib","userId":"04918573300927859168"}},"outputId":"be0a339b-2118-45eb-f915-196eae6ee1f7"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.65900114, 0.24243297, 0.09856589])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["x = torch.tensor([2.0, 1.0, 0.1])\n","outputs = torch.softmax(x, dim =0)\n","outputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qkgubwSpIEGD","executionInfo":{"status":"ok","timestamp":1711445960001,"user_tz":240,"elapsed":147,"user":{"displayName":"Asadullah Hill Galib","userId":"04918573300927859168"}},"outputId":"0d353d4a-7a93-4422-c442-2b2d08d5a614"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.6590, 0.2424, 0.0986])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["def cross_entropy(actual, predicted):\n","  loss = -np.sum(actual * np.log(predicted))\n","  return loss # / float(predicted.shape[0])"],"metadata":{"id":"JGnP6lRkIOL5","executionInfo":{"status":"ok","timestamp":1711446094058,"user_tz":240,"elapsed":172,"user":{"displayName":"Asadullah Hill Galib","userId":"04918573300927859168"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#Y must be one hot encoded\n","Y = np.array([1,0,0])"],"metadata":{"id":"Fkd1a6vFIu72","executionInfo":{"status":"ok","timestamp":1711446107513,"user_tz":240,"elapsed":302,"user":{"displayName":"Asadullah Hill Galib","userId":"04918573300927859168"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["Y_pred_good =  np.array([0.7,0.2,0.1])\n","Y_pred_bad =  np.array([0.1,0.3,0.6])\n","l1  = cross_entropy(Y, Y_pred_good)\n","l2  = cross_entropy(Y, Y_pred_bad)\n","l1, l2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-WpU3QvIyD2","executionInfo":{"status":"ok","timestamp":1711446171098,"user_tz":240,"elapsed":156,"user":{"displayName":"Asadullah Hill Galib","userId":"04918573300927859168"}},"outputId":"c602251b-6161-4999-d225-e4dcb7a1a7c0"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.35667494393873245, 2.3025850929940455)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#Note\n","'''\n","nn.CrossEntropyLoss applies nn.LogSoftmax + nn.NLLLoss (negative log likelihood loss)\n","-> do not use softmax in last layer when using nn.CrossEntropyLoss\n","\n","-> Y has class labels, not one-hot\n","-> Y_pred has raw scores (logits), no softmax\n","\n","'''\n","\n","'''\n","nn.BCELoss does not apply torch.signmoid\n","-> need to use sigmoid in last layer when using nn.BCELoss\n","\n","'''"],"metadata":{"id":"hZOpNVKGJBuA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","\n","\n","Y = torch.tensor([0])\n","# nsamples x nclasses = 1 x 3\n","Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n","Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n","l1 = loss(Y_pred_good,Y)\n","l2 = loss(Y_pred_bad,Y)\n","l1.item(), l2.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2zXCCGYiJ8TE","executionInfo":{"status":"ok","timestamp":1711446826367,"user_tz":240,"elapsed":172,"user":{"displayName":"Asadullah Hill Galib","userId":"04918573300927859168"}},"outputId":"9d1b250c-c861-4279-acf0-29cad50c8176"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.4170299470424652, 1.840616226196289)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["_, predictions1 = torch.max(Y_pred_good, 1)\n","_, predictions2 = torch.max(Y_pred_bad, 1)\n","predictions1, predictions2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nF94tHClKhLV","executionInfo":{"status":"ok","timestamp":1711448048405,"user_tz":240,"elapsed":181,"user":{"displayName":"Asadullah Hill Galib","userId":"04918573300927859168"}},"outputId":"e9b06a53-5a9d-4f6b-d50b-8bbeec42a8fb"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([0]), tensor([1]))"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","\n","# 3 samples\n","Y = torch.tensor([2, 0, 1])\n","# nsamples x nclasses = 3 x 3\n","Y_pred_good = torch.tensor([[0.04, 1.0, 2.1],[2.0, 1.0, 0.1],[0.2, 2.0, 0.1] ])\n","Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3], [0.1, 2.0, 0.1], [2.0, 1.0, 0.1]])\n","l1 = loss(Y_pred_good,Y)\n","l2 = loss(Y_pred_bad,Y)\n","_, predictions1 = torch.max(Y_pred_good, 1)\n","_, predictions2 = torch.max(Y_pred_bad, 1)\n","\n","l1.item(), l2.item(), predictions1, predictions2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJvTTZ5PQL-N","executionInfo":{"status":"ok","timestamp":1711448177894,"user_tz":240,"elapsed":141,"user":{"displayName":"Asadullah Hill Galib","userId":"04918573300927859168"}},"outputId":"50e32bbf-fbed-41d3-af14-97a187849bc1"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.35647499561309814, 1.8731155395507812, tensor([2, 0, 1]), tensor([1, 1, 0]))"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["#how does it work in a typical NN\n","\n","#multiclass problem\n","\n","class NeuralNet2(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_classes):\n","    super(NeuralNet2, self).__init__()\n","    self.linear1 = nn.Linear(input_size, hidden_size)\n","    self.relu = nn.ReLU()\n","    self.linear2 = nn.Linear(hidden_size, num_classes)\n","\n","  def forward(self,x):\n","    out = self.linear1(x)\n","    out = self.relu(out)\n","    out = self.linear2(out)\n","    #no softmax at the end\n","    return out\n","\n","model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n","criterion = nn.CrossEntropyLoss() # applies softmax"],"metadata":{"id":"qQ64bIy1Qrqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#how does it work in a typical NN\n","\n","#binaryclass problem\n","\n","class NeuralNet1(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_classes):\n","    super(NeuralNet2, self).__init__()\n","    self.linear1 = nn.Linear(input_size, hidden_size)\n","    self.relu = nn.ReLU()\n","    self.linear2 = nn.Linear(hidden_size, num_classes)\n","\n","  def forward(self,x):\n","    out = self.linear1(x)\n","    out = self.relu(out)\n","    out = self.linear2(out)\n","    #sigmoid at the end\n","    y_pred = torch.sigmoid(out)\n","    return y_pre\n","\n","model = NeuralNet1(input_size=28*28, hidden_size=5)\n","criterion = nn.BCELoss()"],"metadata":{"id":"wt-VPVR6SC7o"},"execution_count":null,"outputs":[]}]}